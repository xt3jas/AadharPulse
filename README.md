# AadharPulse - Operational Intelligence Platform

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![Polars](https://img.shields.io/badge/Polars-0.20+-orange.svg)](https://pola.rs/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A specialized **Lakehouse** application that ingests Aadhar operational logs and transforms them into strategic insights. The system identifies **Migration**, **Fraud**, and **Operational Volatility** patterns using advanced statistical frameworks.

![Dashboard Preview](docs/dashboard-preview.png)

## ğŸ¯ Key Features

- **Gatekeeper Engine**: Auto-detects CSV schemas and validates data integrity
- **Pulse Analytics**: Calculates 5 niche parameters for operational intelligence
- **Lakehouse Architecture**: Bronze â†’ Silver â†’ Gold data layers with Delta Lake
- **Interactive Dashboard**: 3-tab Streamlit app with drill-downs and exports

## ğŸ“Š The 5 Niche Parameters

| Parameter | Name | Purpose | Threshold |
|-----------|------|---------|-----------|
| **OVS** | Operational Volatility Score | Detect temporary camps vs permanent centers | > 4.0 = Camp |
| **MII** | Migration Impact Index | Identify migration hotspots | > 0.40 = Hotspot |
| **DHR** | Data Hygiene Ratio | Flag potential fraud patterns | > 1.5 = High Risk |
| **TLP** | Temporal Load Profile | Optimize staffing schedules | Weekend/School patterns |
| **SML** | Saturation Maturity Level | Classify district maturity | K-Means clustering |

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- pip or conda

### Installation

```bash
# Clone the repository
cd aadhar_pulse

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running the API

```bash
# Start the FastAPI server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# API documentation available at:
# http://localhost:8000/docs
```

### Running the Dashboard

```bash
# In a new terminal
cd dashboard
streamlit run dashboard.py --server.port 8501

# Dashboard available at:
# http://localhost:8501
```

## ğŸ“¤ Data Ingestion

### CSV Formats

The system auto-detects three types of CSV files:

**Enrolment CSV:**
```csv
date,state,district,pincode,age_0_5,age_5_17,age_18_greater
2024-01-15,KARNATAKA,BANGALORE,560001,100,200,300
```

**Biometric Update CSV:**
```csv
date,state,district,pincode,bio_age_5_17,bio_age_17_
2024-01-15,KARNATAKA,BANGALORE,560001,50,150
```

**Demographic Update CSV:**
```csv
date,state,district,pincode,demo_age_5_17,demo_age_17_
2024-01-15,KARNATAKA,BANGALORE,560001,30,80
```

### Upload via API

```bash
# Upload a CSV file
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@enrolment_data.csv"
```

### Transform Data

```bash
# Transform Bronze to Silver
curl -X POST "http://localhost:8000/api/v1/transform/silver?schema_type=enrolment"
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AadharPulse Architecture                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   CSV       â”‚â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚   Polars    â”‚     â”‚
â”‚  â”‚   Upload    â”‚    â”‚   Gateway   â”‚    â”‚   Engine    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                              â”‚               â”‚
â”‚                                              â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 Delta Lake Storage                   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚  Bronze  â”‚â”€â–¶â”‚  Silver  â”‚â”€â–¶â”‚   Gold   â”‚          â”‚   â”‚
â”‚  â”‚  â”‚  (Raw)   â”‚  â”‚ (Clean)  â”‚  â”‚(Features)â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚               â”‚
â”‚                                              â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Streamlit Dashboard                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚ Command  â”‚  â”‚Operation â”‚  â”‚  Risk &  â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ Center   â”‚  â”‚  Intel   â”‚  â”‚Governanceâ”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
aadhar_pulse/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry point
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py            # API endpoints
â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â””â”€â”€ constants.py         # Thresholds
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ingestion.py         # Data ingestion
â”‚   â”‚   â”œâ”€â”€ analytics.py         # InsightGenerator
â”‚   â”‚   â””â”€â”€ clustering.py        # K-Means SML
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ delta_ops.py         # Delta Lake ops
â”‚       â””â”€â”€ date_parser.py       # Date utilities
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ dashboard.py             # Streamlit app
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ maps.py              # Altair charts
â”‚       â””â”€â”€ metrics.py           # KPI widgets
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                  # Raw data
â”‚   â”œâ”€â”€ silver/                  # Cleaned data
â”‚   â””â”€â”€ gold/                    # Feature tables
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/
â”‚       â”œâ”€â”€ test_ingestion.py
â”‚       â””â”€â”€ test_analytics.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test
pytest tests/unit/test_analytics.py::TestOVSCalculation::test_ovs_high_volatility_spike_pattern -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html
```

## ğŸ³ Docker

```bash
# Build the image
docker build -t aadhar-pulse .

# Run the container
docker run -p 8000:8000 -p 8501:8501 aadhar-pulse
```

## ğŸ“– API Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/ingest` | POST | Upload and validate CSV file |
| `/api/v1/transform/silver` | POST | Transform Bronze to Silver |
| `/api/v1/metrics/summary` | GET | National summary metrics |
| `/api/v1/metrics/district/{name}` | GET | District-level insights |
| `/api/v1/metrics/pincode/{code}` | GET | Pincode-level insights |
| `/api/v1/health` | GET | Health check |

## ğŸ“Š Dashboard Tabs

### Tab 1: Command Center
- National KPI ticker
- District Maturity Map (interactive scatter plot)
- Cluster distribution summary

### Tab 2: Operational Intelligence
- Searchable pincode table sorted by OVS
- Temporal Load Profile chart for selected pincode
- Staffing recommendations

### Tab 3: Risk & Governance
- High-risk district watchlist (DHR > 1.5 or MII > 0.4)
- Vigilance report generation (PDF export)

## ğŸ”§ Configuration

Environment variables (or `.env` file):

```env
APP_NAME=AadharPulse
DEBUG=false
API_HOST=0.0.0.0
API_PORT=8000
```

## ğŸ“ˆ Performance

- **Polars**: Rust-based DataFrame engine for 10-100x faster processing than Pandas
- **Delta Lake**: ACID transactions, time travel, and efficient upserts
- **Async API**: FastAPI with async/await for high concurrency

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Write tests for new functionality
4. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- UIDAI for Aadhar infrastructure
- Polars team for the incredible DataFrame library
- Delta Lake team for the Lakehouse format
